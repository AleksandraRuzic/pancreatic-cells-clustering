{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.metrics import davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_filepaths = [\"GSM2699154/2699154_prep_file3.csv\", \"GSM2699155/2699155_prep_file3.csv\",\n",
    "                     \"GSM2699156/2699156_prep_file3.csv\", \"GSM2699157/2699157_prep_file3.csv\",\n",
    "                     \"GSM3140915/3140915_prep_file3.csv\", \"GSM3140916/3140916_prep_file3.csv\",\n",
    "                     \"GSM3140917/3140917_prep_file3.csv\", \"GSM3140918/3140918_prep_file3.csv\",\n",
    "                     \"GSM3140919/3140919_prep_file3.csv\", \"GSM3140920/3140920_prep_file3.csv\",\n",
    "                     \"GSM3195456/3195456_prep_file3.csv\", \"GSM3488509/3488509_prep_file3.csv\",\n",
    "                     \"GSM3852752/3852752_prep_file3.csv\", \"GSM3852753/3852753_prep_file3.csv\",\n",
    "                     \"GSM3852754/3852754_prep_file3.csv\", \"GSM3852755/3852755_prep_file3.csv\"]\n",
    "\n",
    "colors = [\"red\", \"blue\", \"green\", \"yellow\", \"orange\", \"black\", \"brown\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def km(filename, num_of_clus):\n",
    "    \n",
    "    labels.index = data.index\n",
    "    tsne_data = pd.read_csv(filename[:19] + \"tsne_file.csv\", index_col = 0)\n",
    "    \n",
    "    model = KMeans(num_of_clus)\n",
    "    model.fit(data)\n",
    "    \n",
    "    tsne_data[\"labels\"] = model.labels_\n",
    "    data[\"labels\"] = model.labels_\n",
    "    fig = plt.figure(figsize= (20,15))\n",
    "    for j in range(0, num_of_clus):\n",
    "        plt.scatter(tsne_data[tsne_data.columns[0]][tsne_data['labels'] == j],\n",
    "                    tsne_data[tsne_data.columns[1]][tsne_data['labels'] == j], c=colors[j])\n",
    "    plt.title('KMeans: ' +str(num_of_clus) +' Silhouette Score:' + str(silhouette_score(data, tsne_data['labels']))+\n",
    "              ', CH Score: ' + str(calinski_harabasz_score(data, tsne_data['labels']))+ \n",
    "              ', DB Score: ' + str(davies_bouldin_score(data, tsne_data['labels'])))\n",
    "    fig.savefig(filename[:11]+ \"KM/\" + filename[11:19] + \"KM_\" + str(num_of_clus))\n",
    "    labels[str(num_of_clus)] = model.labels_\n",
    "    \n",
    "    for i in data.columns:\n",
    "        if np.sum(data.loc[:, i] > 0) < 1:\n",
    "            data.drop(i, axis =1, inplace =True)\n",
    "    desc = pd.DataFrame()\n",
    "    for j in range(0, num_of_clus):\n",
    "        df = data.loc[data[\"labels\"] == j].describe().rename(index = lambda x: str(j) + \".cluster_\" + x)\n",
    "        desc = desc.append(df)\n",
    "        desc.to_csv(filename[:11]+ \"KM/KM_\" + str(num_of_clus) + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in list_of_filepaths:\n",
    "    data = pd.read_csv(l, index_col = 0)\n",
    "    labels = pd.DataFrame(columns = [\"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], index = data.index)\n",
    "    for i in range(2, 8):\n",
    "        km(l, i)\n",
    "    labels.to_csv(l[:11]+ \"KM/\" + l[11:19]+ \"labels_KM.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec(filename, num_of_clus):\n",
    "    \n",
    "    model = SpectralClustering(num_of_clus, affinity='nearest_neighbors')\n",
    "    tsne_data = pd.read_csv(filename[:19] + \"tsne_file.csv\", index_col = 0)\n",
    "    \n",
    "    model.fit(data.values)\n",
    "    tsne_data[\"labels\"] = model.labels_\n",
    "    data[\"labels\"] = model.labels_\n",
    "    \n",
    "    fig = plt.figure(figsize= (20,15))\n",
    "    for j in range(0, num_of_clus):\n",
    "        plt.scatter(tsne_data[tsne_data.columns[0]][tsne_data['labels'] == j],\n",
    "                    tsne_data[tsne_data.columns[1]][tsne_data['labels'] == j], c=colors[j])\n",
    "    plt.title('Spectral clus: ' +str(num_of_clus) +' Silhouette Score:' +str(silhouette_score(data, tsne_data['labels']))+\n",
    "              ', CH Score: ' + str(calinski_harabasz_score(data, tsne_data['labels']))+ \n",
    "              ', DB Score: ' + str(davies_bouldin_score(data, tsne_data['labels'])))\n",
    "    fig.savefig(filename[:11]+ \"Spec/\" + filename[11:19] + \"Spec_\" + str(num_of_clus))\n",
    "    labels[str(num_of_clus)] = model.labels_\n",
    "    \n",
    "    for i in data.columns:\n",
    "        if np.sum(data.loc[:, i] > 0) < 1:\n",
    "            data.drop(i, axis =1, inplace =True)\n",
    "    desc = pd.DataFrame()\n",
    "    for j in range(0, num_of_clus):\n",
    "        df = data.loc[data[\"labels\"] == j].describe().rename(index = lambda x: str(j) + \".cluster_\" + x)\n",
    "        desc = desc.append(df)\n",
    "        desc.to_csv(filename[:11]+ \"Spec/Spec_\" + str(num_of_clus) + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in list_of_filepaths:\n",
    "    data = pd.read_csv(l, index_col = 0)\n",
    "    labels = pd.DataFrame(columns = [\"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], index = data.index)\n",
    "    for i in range(2, 8):\n",
    "        spec(l, i)\n",
    "    labels.to_csv(l[:11]+ \"Spec/\" + l[11:19]+ \"labels_spec.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Po grupama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [\"grupe/1.grupa/prep_group.csv\", \"grupe/3.grupa/prep_group.csv\",\n",
    "          \"grupe/4.grupa/prep_group.csv\", \"grupe/2.grupa/prep_group.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.31 GiB for an array with shape (14435, 12208) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-895fd4a2eaf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtsne_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"tsne_file.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtsne_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unnamed: 0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mtsne_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    863\u001b[0m                 _num_samples(X), self.n_clusters))\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m         \u001b[0mtol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tolerance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0;31m# If the distances are precomputed every job will create a matrix of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36m_tolerance\u001b[0;34m(X, tol)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mvariances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_variance_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0mvariances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariances\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvar\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mvar\u001b[0;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[1;32m   3582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3583\u001b[0m     return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n\u001b[0;32m-> 3584\u001b[0;31m                          **kwargs)\n\u001b[0m\u001b[1;32m   3585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_var\u001b[0;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# Note that x may not be inexact and that we need it to be an array,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;31m# not a scalar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0marrmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 1.31 GiB for an array with shape (14435, 12208) and data type float64"
     ]
    }
   ],
   "source": [
    "for filename in groups:\n",
    "    for num_of_clus in range(2,6):\n",
    "        model = KMeans(num_of_clus)\n",
    "        data = pd.read_csv(filename)\n",
    "        data = data.set_index(\"Unnamed: 0\")\n",
    "        #data = data.set_index(\"id\")\n",
    "        data.index.name = None\n",
    "        #tsne_data = pd.read_csv(filename[:19] + \"tsne_file.csv\")\n",
    "        tsne_data = pd.read_csv(filename[:14] + \"tsne_file.csv\")\n",
    "        tsne_data = tsne_data.drop(\"Unnamed: 0\", axis =1)\n",
    "        model.fit(data)\n",
    "        tsne_data[\"labels\"] = model.labels_\n",
    "        data[\"labels\"] = model.labels_\n",
    "        fig = plt.figure(figsize= (20,15))\n",
    "        for j in range(0, num_of_clus):\n",
    "            plt.scatter(tsne_data[tsne_data.columns[0]][tsne_data['labels'] == j],\n",
    "                        tsne_data[tsne_data.columns[1]][tsne_data['labels'] == j], c=colors[j])\n",
    "        plt.title('KMeans: ' +str(num_of_clus) +' Silhouette Score:' +str(silhouette_score(data, tsne_data['labels']))+\n",
    "                  ', CH Score: ' + str(calinski_harabasz_score(data, tsne_data['labels']))+ \n",
    "                  ', DB Score: ' + str(davies_bouldin_score(data, tsne_data['labels'])))\n",
    "        plt.show()\n",
    "        #fig.savefig(filename[:11]+ \"KM/\" + filename[11:19] + \"KM_\" + str(num_of_clus))\n",
    "        fig.savefig(filename[:14]+ \"KM/KM_\" + str(num_of_clus))\n",
    "        labels[\"KM_\"+str(num_of_clus)] = tsne_data[\"labels\"]\n",
    "\n",
    "        for i in data.columns:\n",
    "            if np.sum(data.loc[:, i] > 0) < 1:\n",
    "                data.drop(i, axis =1, inplace =True)\n",
    "        desc = pd.DataFrame()\n",
    "        for j in range(0, num_of_clus):\n",
    "            df = data.loc[data[\"labels\"] == j].describe().rename(index = lambda x: str(j) + \".cluster_\" + x)\n",
    "            desc = desc.append(df)\n",
    "            desc.to_csv(filename[:14]+ \"KM/KM_\" + str(num_of_clus) + \".csv\")\n",
    "    labels.to_csv(filename[:14]+ \"KM/labels_spec.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
